{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d31e6480",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\VScode\\\\bipolar_seesaw_CCM\\\\other_data\\\\monsoon.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# === load & preprocess ===\u001b[39;00m\n\u001b[0;32m     23\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mVScode\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbipolar_seesaw_CCM\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mother_data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmonsoon.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 24\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# interpolate to 10-yr grid\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zps19\\.conda\\envs\\pz_venv_causal\\lib\\site-packages\\pandas\\io\\excel\\_base.py:478\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    477\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 478\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\zps19\\.conda\\envs\\pz_venv_causal\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1496\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1494\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1496\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1501\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1502\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1503\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\zps19\\.conda\\envs\\pz_venv_causal\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1371\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1369\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1371\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1373\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1374\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1375\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zps19\\.conda\\envs\\pz_venv_causal\\lib\\site-packages\\pandas\\io\\common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\VScode\\\\bipolar_seesaw_CCM\\\\other_data\\\\monsoon.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === your GS reference data ===\n",
    "gs_data = {\n",
    "    \"start\": [11703,14692,23020,23340,27780,28900,30840,32500,\n",
    "              33740,35480,38220,40160,41460,43340,46860,49280,\n",
    "              54220,55000,55800,58040,58280,59080,59440,64100,\n",
    "              69620,72340,76440,84760,85060,90040,\n",
    "              104040,104520,106750,108280,115370],\n",
    "    \"end\":   [12896,22900,23220,27540,28600,30600,32040,33360,\n",
    "              34740,36580,39900,40800,42240,44280,48340,49600,\n",
    "              54900,55400,56500,58160,58560,59300,63840,69400,\n",
    "              70380,74100,77760,84960,87600,90140,\n",
    "              104380,105440,106900,110640,119140]\n",
    "}\n",
    "\n",
    "# === load & preprocess ===\n",
    "file_path = r\"D:\\VScode\\bipolar_seesaw_CCM\\other_data\\monsoon.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "df['age'] = df['age'] * 1000\n",
    "\n",
    "# interpolate to 10-yr grid\n",
    "new_age = np.arange(0, int(df['age'].max())+10, 10)\n",
    "f = interp1d(df['age'], df['d18O'], kind='nearest',\n",
    "             bounds_error=False, fill_value=1)\n",
    "interpolated = f(new_age)\n",
    "new_df = pd.DataFrame({'age': new_age, 'd18O': interpolated})\n",
    "\n",
    "# low-frequency smooth\n",
    "new_df['smoothed'] = new_df['d18O'].rolling(1000, center=True, min_periods=1).mean()\n",
    "# millennial signal\n",
    "new_df['d18O_ms'] = new_df['d18O'] - new_df['smoothed']\n",
    "# extra smooth + first difference\n",
    "new_df['d18O_ms']   = new_df['d18O_ms'].rolling(50, center=True, min_periods=1).mean()\n",
    "new_df['d18O_diff'] = new_df['d18O_ms'].diff().fillna(0).rolling(15, center=True, min_periods=1).mean()\n",
    "\n",
    "# === build figure with 2 rows ===\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.05,\n",
    "    subplot_titles=(\"d18O vs Age\", \"d18O_diff vs Age\")\n",
    ")\n",
    "\n",
    "# top panel: d18O\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=new_df['age'], y=new_df['d18O_ms'], mode='lines', name='d18O'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# bottom panel: diff\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=new_df['age'], y=new_df['d18O_diff'],\n",
    "               mode='lines', name='d18O_diff', line=dict(color='red')),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# === add GS vertical strips to the diff panel ===\n",
    "for s, e in zip(gs_data['start'], gs_data['end']):\n",
    "    fig.add_vrect(\n",
    "        x0=s, x1=e,\n",
    "        fillcolor='LightSalmon', opacity=0.3,\n",
    "        line_width=0,\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# === layout tweaks ===\n",
    "fig.update_layout(\n",
    "    height=900, width=1800,\n",
    "    showlegend=False,\n",
    "    title_text=\"Monsoon δ¹⁸O and Its First Difference (with GS periods)\"\n",
    ")\n",
    "\n",
    "# axes labels\n",
    "fig.update_xaxes(title_text=\"Age (years)\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"d18O\",      row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"d18O_diff\", row=2, col=1)\n",
    "\n",
    "# add range-slider on the diff panel\n",
    "fig.update_xaxes(rangeslider=dict(visible=True), row=2, col=1)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a072e144",
   "metadata": {},
   "source": [
    " find peaks corresponse to start, valley corresponds to end, set the tolerrence to be 50 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d01eb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "\n",
    "# 1. reference GS data (yrs)\n",
    "gs_data = {\n",
    "    \"start\": [11703,14692,23020,23340,27780,28900,30840,32500,\n",
    "              33740,35480,38220,40160,41460,43340,46860,49280,\n",
    "              54220,55000,55800,58040,58280,59080,59440,64100,\n",
    "              69620,72340,76440,84760,85060,90040,\n",
    "              104040,104520,106750,108280,115370],\n",
    "    \"end\":   [12896,22900,23220,27540,28600,30600,32040,33360,\n",
    "              34740,36580,39900,40800,42240,44280,48340,49600,\n",
    "              54900,55400,56500,58160,58560,59300,63840,69400,\n",
    "              70380,74100,77760,84960,87600,90140,\n",
    "              104380,105440,106900,110640,119140]\n",
    "}\n",
    "gs_intervals = np.column_stack((gs_data['start'], gs_data['end']))\n",
    "\n",
    "# 2. enforce 1:1 alternation\n",
    "def pair_peaks_valleys(peaks, valleys):\n",
    "    peaks, valleys = np.sort(peaks), np.sort(valleys)\n",
    "    i, j = 0, 0\n",
    "    pairs = []\n",
    "    # skip any valley before first peak\n",
    "    while j < len(valleys) and valleys[j] < peaks[0]:\n",
    "        j += 1\n",
    "    while i < len(peaks) and j < len(valleys):\n",
    "        s = peaks[i]\n",
    "        # advance valley until > s\n",
    "        while j < len(valleys) and valleys[j] < s:\n",
    "            j += 1\n",
    "        if j == len(valleys): break\n",
    "        e = valleys[j]\n",
    "        pairs.append((s, e))\n",
    "        # skip peaks up to this valley\n",
    "        i += 1\n",
    "        while i < len(peaks) and peaks[i] <= e:\n",
    "            i += 1\n",
    "        j += 1\n",
    "    return np.array(pairs)  # shape (N,2)\n",
    "\n",
    "# 3. new F1 based on overlap\n",
    "def compute_f1_from_intervals(ages, known_intervals, pred_intervals):\n",
    "    # build binary masks\n",
    "    known_mask = np.zeros_like(ages, dtype=bool)\n",
    "    for s,e in known_intervals:\n",
    "        known_mask[(ages >= s) & (ages <= e)] = True\n",
    "    pred_mask = np.zeros_like(ages, dtype=bool)\n",
    "    for s,e in pred_intervals:\n",
    "        pred_mask[(ages >= s) & (ages <= e)] = True\n",
    "\n",
    "    tp = np.sum(pred_mask & known_mask)\n",
    "    fp = np.sum(pred_mask & ~known_mask)\n",
    "    fn = np.sum(~pred_mask & known_mask)\n",
    "\n",
    "    prec = tp/(tp+fp) if tp+fp>0 else 0\n",
    "    rec  = tp/(tp+fn) if tp+fn>0 else 0\n",
    "    return 2*prec*rec/(prec+rec) if (prec+rec)>0 else 0\n",
    "\n",
    "# 4. crop ≤120 ka\n",
    "df_crop   = new_df[new_df['age'] <= 120_000].copy()\n",
    "ages_crop = df_crop['age'].values\n",
    "diff_crop = df_crop['d18O_diff'].values\n",
    "\n",
    "# 5. sweep thresholds to maximize new F1\n",
    "upper_grid = np.linspace(np.quantile(diff_crop,0.50),\n",
    "                         np.quantile(diff_crop,0.99), 100)\n",
    "lower_grid = np.linspace(np.quantile(diff_crop,0.01),\n",
    "                         np.quantile(diff_crop,0.50), 100)\n",
    "\n",
    "best_f1 = -1\n",
    "for ut in upper_grid:\n",
    "    # candidate starts\n",
    "    pk_idx, _ = find_peaks(diff_crop, height=ut, distance=50)\n",
    "    pk_ages   = ages_crop[pk_idx]\n",
    "    for lt in lower_grid:\n",
    "        # candidate ends\n",
    "        vl_idx, _ = find_peaks(-diff_crop, height=-lt, distance=50)\n",
    "        vl_ages   = ages_crop[vl_idx]\n",
    "        # enforce alternation\n",
    "        pairs = pair_peaks_valleys(pk_ages, vl_ages)\n",
    "        if pairs.size == 0:\n",
    "            continue\n",
    "        f1 = compute_f1_from_intervals(ages_crop, gs_intervals, pairs)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best = {\n",
    "                'upper': ut, 'lower': lt,\n",
    "                'pairs_crop': pairs,\n",
    "                'f1': f1\n",
    "            }\n",
    "\n",
    "print(f\"Best thresholds → upper={best['upper']:.3e}, lower={best['lower']:.3e}, F1={best['f1']:.3f}\")\n",
    "\n",
    "# 6. apply to full record\n",
    "ages_full = new_df['age'].values\n",
    "diff_full = new_df['d18O_diff'].values\n",
    "pkf, _ = find_peaks(diff_full,  height=best['upper'], distance=50)\n",
    "vlf, _ = find_peaks(-diff_full, height=-best['lower'], distance=50)\n",
    "pairs_full = pair_peaks_valleys(ages_full[pkf], ages_full[vlf])\n",
    "\n",
    "# build square waves\n",
    "sq_crop = np.ones_like(ages_crop)\n",
    "for s,e in best['pairs_crop']:\n",
    "    sq_crop[(ages_crop>=s)&(ages_crop<=e)] = -1\n",
    "\n",
    "sq_full = np.ones_like(ages_full)\n",
    "for s,e in pairs_full:\n",
    "    sq_full[(ages_full>=s)&(ages_full<=e)] = -1\n",
    "\n",
    "# 7a. plot ≤120 ka\n",
    "fig, ax = plt.subplots(figsize=(20,4))\n",
    "for s,e in gs_intervals:      ax.axvspan(s, e, alpha=0.2, color='grey')\n",
    "for s,e in best['pairs_crop']:ax.axvspan(s, e, alpha=0.1, color='red')\n",
    "ax.plot(ages_crop, df_crop['d18O'], label='d18O')\n",
    "ax.plot(ages_crop, sq_crop*np.max(abs(df_crop['d18O'])), label='GS signal')\n",
    "ax.set_title(f\"≤120 ka: Known vs Detected GS (F1={best['f1']:.2f})\")\n",
    "ax.set_xlabel(\"Age (yr)\")\n",
    "ax.legend()\n",
    "\n",
    "# 7b. plot full record\n",
    "fig2, ax2 = plt.subplots(figsize=(20,4))\n",
    "for s,e in pairs_full:        ax2.axvspan(s, e, alpha=0.2, color='red')\n",
    "ax2.plot(ages_full, new_df['d18O'], label='d18O')\n",
    "ax2.plot(ages_full, sq_full*np.max(abs(new_df['d18O'])), label='GS signal')\n",
    "ax2.set_title(\"Full Record: Detected GS\")\n",
    "ax2.set_xlabel(\"Age (yr)\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd7951b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
